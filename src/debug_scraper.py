import json
import time
import random
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import google.generativeai as genai
import os
from dotenv import load_dotenv

load_dotenv()

class DebugScraper:
    def __init__(self):
        self.reviews_data = []
        self.business_info = {}
        self.debug_messages = []
        
        # Setup Gemini
        try:
            genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
            self.model = genai.GenerativeModel('gemini-1.5-flash')
            self.log("âœ… Gemini API configured")
        except Exception as e:
            self.log(f"âŒ Gemini setup failed: {e}")
    
    def log(self, message):
        """Log debug messages"""
        print(message)
        self.debug_messages.append(message)
    
    def setup_driver(self):
        """Setup Chrome with detailed error handling"""
        try:
            self.log("ğŸ”§ Setting up Chrome driver...")
            
            options = Options()
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)
            
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
            
            self.log("âœ… Chrome driver ready")
            return driver
            
        except Exception as e:
            self.log(f"âŒ Chrome setup failed: {e}")
            return None
    
    async def scrape_reviews(self, url, max_reviews=100):
        """Debug scraping with detailed logging"""
        driver = None
        try:
            self.log(f"ğŸ¯ Starting scrape for: {url}")
            
            # Setup driver
            driver = self.setup_driver()
            if not driver:
                self.log("âŒ Failed to create Chrome driver")
                return []
            
            # Load page
            self.log("ğŸŒ Loading Google Maps page...")
            driver.get(url)
            time.sleep(5)
            
            # Get business name
            try:
                business_element = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "h1"))
                )
                business_name = business_element.text
                self.business_info = {
                    'name': business_name,
                    'url': url,
                    'scraped_at': datetime.now().isoformat()
                }
                self.log(f"ğŸ¢ Found business: {business_name}")
            except:
                self.business_info = {'name': 'Unknown', 'url': url, 'scraped_at': datetime.now().isoformat()}
            
            # Navigate to reviews section
            self.log("ğŸ” Looking for reviews tab...")
            reviews_tab_found = False
            
            # Try multiple selectors for reviews tab
            reviews_tab_selectors = [
                'button[data-value="Sort"]',
                'button[aria-label*="review" i]',
                'button[aria-label*="Reviews" i]',
                '.hh2c6',
                '[role="tab"][aria-label*="review" i]'
            ]
            
            for selector in reviews_tab_selectors:
                try:
                    reviews_tab = WebDriverWait(driver, 5).until(
                        EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                    )
                    if reviews_tab:
                        driver.execute_script("arguments[0].click();", reviews_tab)
                        time.sleep(3)
                        self.log(f"âœ… Clicked reviews tab with selector: {selector}")
                        reviews_tab_found = True
                        break
                except:
                    continue
            
            if not reviews_tab_found:
                self.log("âš ï¸ Reviews tab not found, trying to scroll to find reviews...")
            
            # More aggressive scrolling and review loading
            self.log(f"ğŸ“œ Aggressively loading reviews...")
            
            # Wait for initial reviews to load
            time.sleep(3)
            
            for scroll in range(25):  # More scroll attempts
                # Scroll to bottom
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1.5)
                
                # Try to find and click "Show more" or "More reviews" buttons
                show_more_selectors = [
                    '[aria-label*="more" i]',
                    '.w8nwRe',
                    'button[jsaction*="review"]',
                    '.gws-localreviews__google-reviews',
                    '[data-value="Sort"] ~ button'
                ]
                
                for selector in show_more_selectors:
                    try:
                        buttons = driver.find_elements(By.CSS_SELECTOR, selector)
                        for btn in buttons[:2]:
                            if btn.is_displayed() and btn.is_enabled():
                                driver.execute_script("arguments[0].click();", btn)
                                time.sleep(1)
                    except:
                        continue
                
                # Count reviews with multiple selectors
                review_selectors = [
                    '[data-review-id]',
                    '.jftiEf',
                    '.MyEned',
                    '[jsaction*="review"]',
                    '.wiI7pd'
                ]
                
                max_found = 0
                for selector in review_selectors:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    max_found = max(max_found, len(elements))
                
                self.log(f"   Scroll {scroll+1}: Found {max_found} reviews")
                
                if max_found >= max_reviews or max_found > 50:
                    self.log(f"âœ… Found sufficient reviews: {max_found}")
                    break
                    
                # Random delay to avoid detection
                time.sleep(random.uniform(0.5, 1.5))
            
            # Extract reviews using multiple selectors
            all_review_elements = []
            review_selectors = [
                '[data-review-id]',
                '.jftiEf',
                '.MyEned',
                '[jsaction*="review"]'
            ]
            
            for selector in review_selectors:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    all_review_elements = elements
                    self.log(f"ğŸ” Using selector {selector}: found {len(elements)} elements")
                    break
            
            if all_review_elements:
                self.log("ğŸ“‹ Extracting review content...")
                reviews = self.extract_review_content(driver, all_review_elements)
                
                # Filter out reviews with "Unknown" names and default text
                real_reviews = [r for r in reviews if r['reviewer_name'] != 'Unknown' and len(r['review_text']) > 20]
                
                if real_reviews:
                    self.reviews_data = real_reviews
                    self.log(f"âœ… Successfully extracted {len(real_reviews)} real reviews!")
                    return real_reviews
                elif reviews:
                    self.reviews_data = reviews
                    self.log(f"âœ… Extracted {len(reviews)} reviews (some may be incomplete)")
                    return reviews
            
            # Fallback: Create sample data
            self.log("ğŸ”„ Using sample data as fallback...")
            sample_reviews = [
                {
                    "reviewer_name": "Sample Customer 1",
                    "rating": 4,
                    "review_text": "Good food and service. Pizza was delivered hot and on time.",
                    "review_date": "2 months ago"
                },
                {
                    "reviewer_name": "Sample Customer 2",
                    "rating": 5,
                    "review_text": "Excellent experience! Great taste and fast delivery.",
                    "review_date": "1 month ago"
                },
                {
                    "reviewer_name": "Sample Customer 3",
                    "rating": 3,
                    "review_text": "Average pizza. Could be better but not bad.",
                    "review_date": "3 weeks ago"
                }
            ]
            
            self.reviews_data = sample_reviews
            self.log(f"âœ… Using {len(sample_reviews)} sample reviews for testing")
            return sample_reviews
            
        except Exception as e:
            self.log(f"âŒ Scraping error: {e}")
            return []
        finally:
            if driver:
                driver.quit()
                self.log("ğŸ”’ Chrome driver closed")
    
    def extract_review_content(self, driver, review_containers):
        """Extract specific review content from the page"""
        try:
            review_data_list = []
            
            self.log(f"ğŸ“‹ Found {len(review_containers)} review containers")
            
            for i, container in enumerate(review_containers):
                try:
                    # Extract reviewer name with more selectors
                    name_selectors = [
                        '.d4r55',
                        '[data-attrid="title"]', 
                        '.X43Kjb',
                        '.TSUbDb a',
                        '.TSUbDb',
                        '.WNxzHc span',
                        '.WNxzHc'
                    ]
                    reviewer_name = f"Reviewer_{i+1}"  # Better default
                    for selector in name_selectors:
                        try:
                            name_elem = container.find_element(By.CSS_SELECTOR, selector)
                            if name_elem and name_elem.text and len(name_elem.text.strip()) > 0:
                                reviewer_name = name_elem.text.strip()
                                break
                        except:
                            continue
                    
                    # Extract rating with more selectors
                    rating = 4  # Default rating
                    rating_selectors = [
                        '[role="img"][aria-label*="star"]',
                        '.kvMYJc[role="img"]',
                        '[aria-label*="stars"]',
                        '.lTi8oc'
                    ]
                    for selector in rating_selectors:
                        try:
                            rating_elem = container.find_element(By.CSS_SELECTOR, selector)
                            rating_text = rating_elem.get_attribute('aria-label')
                            if rating_text and rating_text[0].isdigit():
                                rating = int(rating_text.split()[0])
                                break
                        except:
                            continue
                    
                    # Extract review text with comprehensive selectors
                    text_selectors = [
                        '.wiI7pd',
                        '.MyEned span',
                        '.rsqaWe',
                        '.ODSEW-ShBeI-text',
                        '.ODSEW-ShBeI-ShBeI-content',
                        '.review-text',
                        '[data-expandable-section]'
                    ]
                    review_text = f"Review from {reviewer_name}"
                    for selector in text_selectors:
                        try:
                            text_elem = container.find_element(By.CSS_SELECTOR, selector)
                            if text_elem and text_elem.text and len(text_elem.text.strip()) > 10:
                                review_text = text_elem.text.strip()
                                break
                        except:
                            continue
                    
                    # Extract date with more selectors
                    date_selectors = [
                        '.rsqaWe',
                        '.p34Ii', 
                        '.DU9Pgb',
                        '.ODSEW-ShBeI-RgZmSc-date',
                        '.dehysf',
                        '.WMbnJf'
                    ]
                    review_date = "Recent"
                    for selector in date_selectors:
                        try:
                            date_elem = container.find_element(By.CSS_SELECTOR, selector)
                            if date_elem and date_elem.text and len(date_elem.text.strip()) > 0:
                                review_date = date_elem.text.strip()
                                break
                        except:
                            continue
                    
                    # Create review data
                    review_data = {
                        'reviewer_name': reviewer_name,
                        'rating': rating,
                        'review_text': review_text,
                        'review_date': review_date
                    }
                    
                    review_data_list.append(review_data)
                    self.log(f"   Review {i+1}: {reviewer_name} - {rating} stars")
                    
                except Exception as e:
                    self.log(f"   Error extracting review {i+1}: {e}")
                    continue
            
            self.log(f"ğŸ“‹ Successfully extracted {len(review_data_list)} reviews")
            return review_data_list
            
        except Exception as e:
            self.log(f"âŒ Direct extraction failed: {e}")
            return []
    
    def clear_data(self):
        """Clear all scraper data for new analysis"""
        self.reviews_data = []
        self.business_info = {}
        self.debug_messages = []
        self.log("ğŸ§¹ Cleared all scraper data for new analysis")
    
    def get_debug_log(self):
        """Get all debug messages"""
        return "\n".join(self.debug_messages)

# Create instance
debug_scraper = DebugScraper()